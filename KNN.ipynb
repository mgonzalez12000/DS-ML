{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bfea9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83cfa7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width    species\n",
      "0             5.1          3.5           1.4          0.2     setosa\n",
      "1             4.9          3.0           1.4          0.2     setosa\n",
      "2             4.7          3.2           1.3          0.2     setosa\n",
      "3             4.6          3.1           1.5          0.2     setosa\n",
      "4             5.0          3.6           1.4          0.2     setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145           6.7          3.0           5.2          2.3  virginica\n",
      "146           6.3          2.5           5.0          1.9  virginica\n",
      "147           6.5          3.0           5.2          2.0  virginica\n",
      "148           6.2          3.4           5.4          2.3  virginica\n",
      "149           5.9          3.0           5.1          1.8  virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# A) Read the iris flower dataset from the following \n",
    "# URL: https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv (Links to an external site.) \n",
    "# and assign it to a Pandas DataFrame as you learned in tutorial Lab2-3. \n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e70d94d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Split the dataset into testing and training sets with the following parameters: test_size=0.4, random_state=6\n",
    "# create a python list of feature names that would like to pick from the dataset:\n",
    "feature_cols = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "# use the above list to select the features from the original DataFrame\n",
    "X = df[feature_cols]  \n",
    "y = df['species']\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9c83111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# C) Instantiate a KNN object with K = 3, train it on the training set and test it on the\n",
    "# testing set. Then, calculate the accuracy of your prediction as you learned in lab 3\n",
    "k = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "# Training only on the the data set:\n",
    "knn.fit(X_train, y_train)\n",
    "# Testing only on the testing set:\n",
    "y_predict = knn.predict(X_test)\n",
    "# Calculate the accuracy of your prediction\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print('The accuracy is:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f46e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95, 0.9833333333333333, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9166666666666666, 0.8166666666666667]\n"
     ]
    }
   ],
   "source": [
    "# D) Repeat part (c) for K=1, K=5, K=7, K=11, K=15, K=27, K=59 (you can simply use a “for loop,” \n",
    "# and save the final accuracy results in a list).\n",
    "k_list = [1, 5, 7, 11, 15, 27, 59]\n",
    "result = []\n",
    "for i in range(len(k_list)):\n",
    "    # Instantiate a KNN object with K=3, train it on the training set and test it on the testing set. \n",
    "    # Then, calculate the accuracy of your prediction as you learned in Lab3.\n",
    "    k = k_list[i]\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Training only on the the data set:\n",
    "    knn.fit(X_train, y_train)\n",
    "    # Testing only on the testing set:\n",
    "    y_predict = knn.predict(X_test)\n",
    "    # Calculate the accuracy of your prediction\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    result.append(accuracy)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced00423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy does NOT always get better by increasing the value of k as shown in [0.95, 0.9833333333333333, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9166666666666666, 0.8166666666666667]\n"
     ]
    }
   ],
   "source": [
    "# Does the accuracy always get better by increasing the value K?\n",
    "print('The accuracy does NOT always get better by increasing the value of k as shown in', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e07ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7166666666666667, 0.55, 0.9666666666666667, 0.95]\n"
     ]
    }
   ],
   "source": [
    "# E) Now, suppose that we would like to make prediction based on only ONE single feature. \n",
    "# To find the best single feature, we have to try every feature individually. \n",
    "# In other word, we have to repeat part (c) with K=3, four times (each time using only one of the 4 features), \n",
    "# and compute the accuracy each time. Then, check the accuracies.  \n",
    "# (Note: you have to train, test, and evaluate your model 4 times, each time on a dataset including only one of the features, and save the final accuracy results in a list).\n",
    "\n",
    "# create a python list of feature names that would like to pick from the dataset:\n",
    "feature_cols = [['sepal_length'], ['sepal_width'], ['petal_length'], ['petal_width']]\n",
    "result = []\n",
    "for i in range(len(feature_cols)):\n",
    "    # use the above list to select the features from the original DataFrame\n",
    "    X = df[feature_cols[i]]  \n",
    "    y = df['species']\n",
    "    # Splitting the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=6)\n",
    "    # Instaniating Knn object\n",
    "    k = 3\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Training only on the the data set:\n",
    "    knn.fit(X_train, y_train)\n",
    "    # Testing only on the testing set:\n",
    "    y_predict = knn.predict(X_test)\n",
    "    # Calculate the accuracy of your prediction\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    result.append(accuracy)\n",
    "print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63aa2e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beat feature the provides the best accuracy is petal_length which has an accuracy of 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Which individual feature provide the best accuracy (the best feature)?  \n",
    "print('The beat feature the provides the best accuracy is petal_length which has an accuracy of ' + str(result[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cca36ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual feature that provides the SECOND best accuracy is petal_width which has an accuracy of: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Which one is the second best feature? \n",
    "print('Individual feature that provides the SECOND best accuracy is petal_width which has an accuracy of: '+ str(result[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d4db135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7833333333333333, 0.9833333333333333, 0.95, 0.9833333333333333, 0.95, 0.9666666666666667]\n"
     ]
    }
   ],
   "source": [
    "# F) Now, we want to repeat part (e), this time using two features. you have to train, test, and evaluate your model for 6 different cases: using (1st and 2nd features), (1st and 3rd features), (1st and 4th  features), (2nd  and 3rd  features), (2nd and 4th features), (3rd and 4th  features)!    \n",
    "# Which “feature pair” provides the best accuracy?\n",
    "# create a python list of feature names that would like to pick from the dataset:\n",
    "feature_cols = [['sepal_length', 'sepal_width'], ['sepal_width', 'petal_length'], ['sepal_length', 'petal_width'], ['sepal_width', 'petal_length'], ['sepal_width', 'petal_width'], ['petal_length', 'petal_width']]\n",
    "result = []\n",
    "for i in range(len(feature_cols)):\n",
    "    # use the above list to select the features from the original DataFrame\n",
    "    X = df[feature_cols[i]]  \n",
    "    y = df['species']\n",
    "    # Splitting the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=6)\n",
    "    # Instaniating Knn object\n",
    "    k = 3\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Training only on the the data set:\n",
    "    knn.fit(X_train, y_train)\n",
    "    # Testing only on the testing set:\n",
    "    y_predict = knn.predict(X_test)\n",
    "    # Calculate the accuracy of your prediction\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    result.append(accuracy)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2cd9503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature pair that provides the best accuracy is either 1st and 3rd features or 2nd and 3rd features.\n"
     ]
    }
   ],
   "source": [
    "# Which “feature pair” provides the best accuracy?\n",
    "print('The feature pair that provides the best accuracy is either 1st and 3rd features or 2nd and 3rd features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f66e93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both feature pairs contain the first best feature but do not contain the second best feature. Therefore, we cannot conclude that the best two features for classification are the first best feature along with second best feature together\n"
     ]
    }
   ],
   "source": [
    "# G) Big Question: Does the “best feature pair” from part (f) contain of both “first best feature” \n",
    "# and “second best feature” from part (e)? In other word, can we conclude that the “best two features” \n",
    "# for classification are the first best feature along with the second best feature together?\n",
    "# H) Optional Question: Justify your answer for part (g)! If yes, why?  If no, why not?\n",
    "print('Both feature pairs contain the first best feature but do not contain the second best feature. Therefore, we cannot conclude that the best two features for classification are the first best feature along with second best feature together')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c2216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
